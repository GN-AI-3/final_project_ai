import json
from langchain.schema import HumanMessage
from agents.food.llm_config import llm
from agents.food.tool.recommend_diet_tool import tool_list
from agents.food.agent_state import AgentState

tool_map = {tool.name: tool for tool in tool_list}

def retry_node(state: AgentState) -> AgentState:
    parsed_plan = state.parsed_plan or {}
    tool_result = state.tool_result or ""
    tool_name = parsed_plan.get("tool_name", "")
    user_input = state.user_input
    member_id = state.member_id
    context = state.context or {}
    retry_count = state.retry_count or 0
    max_retry = 2

    # âœ… í‰ê°€ ëŒ€ìƒ ë„êµ¬ ëª©ë¡
    evaluatable_tools = {"recommend_diet_tool", "record_meal_tool"}

    # 1ï¸âƒ£ ì‚¬ìš©ì ì •ë³´ ì €ì¥ ë„êµ¬ì¸ ê²½ìš°
    if tool_name == "save_user_goal_and_diet_info" and "ì¶”ì¶œëœ ì •ë³´" in tool_result:
        prompt = f"""
        ì•„ë˜ëŠ” ì‚¬ìš©ìì˜ ì…ë ¥ê³¼ ì €ì¥ëœ ì •ë³´ì•¼.
        ì´ ì •ë„ ì •ë³´ë©´ ì‹ë‹¨ ì¶”ì²œì´ ê°€ëŠ¥í•œê°€?

        [ì‚¬ìš©ì ì…ë ¥]
        {user_input}

        [ì €ì¥ ê²°ê³¼]
        {tool_result}

        ì¶”ê°€ ì •ë³´ê°€ ë” í•„ìš”í•˜ë©´ "planner"ë¡œ ë³´ë‚´ê³ ,
        ì¶©ë¶„í•˜ë‹¤ë©´ "final"ë¡œ ì¢…ë£Œí•´ì¤˜.

        í˜•ì‹: planner / final
        """
        response = llm.invoke([HumanMessage(content=prompt)]).content.strip().lower()
        if response == "planner":
            return state.copy(update={
                "retry_count": retry_count + 1,
                "agent_out": "â„¹ï¸ ì €ì¥ëœ ì •ë³´ëŠ” ì¶©ë¶„í•˜ì§€ ì•Šì•„ ì¶”ê°€ ì§ˆë¬¸ í•„ìš”",
                "context": {**context, "user_profile_saved": True}
            })
        return state.copy(update={
            "agent_out": "âœ… ì‚¬ìš©ì ì •ë³´ ì €ì¥ ì™„ë£Œ ë° ì¶©ë¶„í•¨",
            "context": {**context, "user_profile_saved": True}
        })
    if state.tool_name == "record_meal_tool":
        return state.copy(update={
            "agent_out": "âœ… ì‹ì‚¬ ê¸°ë¡ ë„êµ¬ëŠ” í‰ê°€ ì—†ì´ ì™„ë£Œë©ë‹ˆë‹¤.",
            "next_node": "refine"
        })
    # âœ… í‰ê°€ ëŒ€ìƒì´ ì•„ë‹Œ ë„êµ¬ì¼ ê²½ìš° â†’ í‰ê°€ ìƒëµ
    if tool_name not in evaluatable_tools:
        return state.copy(update={
            "agent_out": f"â„¹ï¸ í‰ê°€ ìƒëµ: {tool_name} ë„êµ¬ëŠ” í‰ê°€ ëŒ€ìƒì´ ì•„ë‹™ë‹ˆë‹¤.",
            "context": context
        })

    # 2ï¸âƒ£ í”¼ë“œë°± ë„êµ¬ í™•ì¸
    feedback_tool = tool_map.get("diet_feedback_tool")
    if not feedback_tool:
        return state.copy(update={
            "agent_out": "âš ï¸ í‰ê°€ ë„êµ¬(diet_feedback_tool)ê°€ ì—†ì–´ ê²°ê³¼ë¥¼ ê·¸ëŒ€ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.",
            "context": context
        })

    # 3ï¸âƒ£ ë„êµ¬ í”¼ë“œë°± í‰ê°€
    try:
        feedback = feedback_tool.invoke({"params": {
            "input": tool_result,
            "member_id": member_id,
            "context": context
        }})
        parsed_feedback = json.loads(feedback)
        context["diet_feedback"] = feedback

        # 3-1ï¸âƒ£ ê²°ê³¼ ë¶€ì ì ˆ â†’ ì¬ì‹œë„ or í”Œë˜ë„ˆ or fallback
        if not parsed_feedback.get("valid", True):
            suggestion = parsed_feedback.get("suggestion", "")
            retry_tool = tool_map.get(tool_name)
            retry_input = parsed_plan.get("tool_input", {})

            # 1ì°¨: ë„êµ¬ ì¬ì‹¤í–‰
            if retry_count == 0 and retry_tool:
                if isinstance(retry_input, dict):
                    retry_input["input"] = retry_input.get("input", "") + f" ({suggestion})"
                retry_result = retry_tool.invoke({"params": {
                    "input": retry_input,
                    "member_id": member_id,
                    "context": context
                }})
                return state.copy(update={
                    "retry_count": retry_count + 1,
                    "context": context,
                    "tool_result": retry_result,
                    "agent_out": f"ğŸ” ì¬ì¶”ì²œ ì‹¤í–‰ë¨ (1ì°¨)\nâ†’ {retry_result}"
                })

            # 2ì°¨: planner ì¬ì‹¤í–‰
            if retry_count == 1:
                return state.copy(update={
                    "retry_count": retry_count + 1,
                    "agent_out": "ğŸ§  ì¬ì‹œë„ ì‹¤íŒ¨ â†’ ì „ì²´ í”Œë˜ë„ˆ ì¬ì‹¤í–‰",
                    "next_node": "planner",
                    "context": context
                })

            # 3ì°¨: LLM Fallback ì‘ë‹µ
            fallback_prompt = f"""
            ë„êµ¬ ê²°ê³¼ê°€ ì¶©ë¶„í•˜ì§€ ì•Šì•„ì„œ {max_retry}íšŒ ì´ìƒ ì¬ì‹œë„í–ˆì§€ë§Œ ì‹¤íŒ¨í–ˆì–´.

            [ì‚¬ìš©ì ì…ë ¥]
            {user_input}

            [í˜„ì¬ context ì •ë³´]
            {json.dumps(context, ensure_ascii=False)}

            [ë„êµ¬ ì‹¤í–‰ ê²°ê³¼]
            {tool_result}

            ì´ ìƒí™©ì„ ê³ ë ¤í•´ì„œ LLMì´ ì§ì ‘ ì‚¬ìš©ìì—ê²Œ ì ì ˆí•œ ì‘ë‹µì„ ìƒì„±í•´ì¤˜.
            """
            response = llm.invoke([HumanMessage(content=fallback_prompt)])
            return state.copy(update={
                "agent_out": f"ğŸ¤– ë„êµ¬ ì‹¤íŒ¨ â†’ LLMì´ ì§ì ‘ ì‘ë‹µ ìƒì„±\nâ†’ {response.content.strip()}",
                "context": context
            })

        # 3-2ï¸âƒ£ ê²°ê³¼ ì ì ˆ
        return state.copy(update={
            "agent_out": f"âœ… ê²°ê³¼ í‰ê°€ ì™„ë£Œ: ì ì ˆí•œ ê²°ê³¼ì…ë‹ˆë‹¤.\nâ†’ {tool_result}",
            "context": context
        })

    except Exception as e:
        return state.copy(update={
            "agent_out": f"âŒ í‰ê°€ ë˜ëŠ” ì¬ì‹œë„ ì‹¤íŒ¨\n{str(e)}",
            "retry_count": retry_count + 1,
            "context": context
        })
